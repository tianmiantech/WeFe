# ************************************************
# The configuration for job
# ************************************************

# Environment name, different configuration files for different environments .
# Enums: prod、dev、fat、none
# Default is none
env.name=prod

# Different branches have different functions
# Enums: master、online_demo
env.branch=master

# The configuration of the backend used by the task
# Contains the following definitions:LOCAL, SPARK, FC
# LOCAL: The stand-alone calculation is only used for local debugging code. It must be used with LMDB at present
# SPARK: SPARK is currently the recommended calculation method, it is recommended to use it with CLICKHOUSE.
# FC: Function computing is an elastic computing solution combined with cloud, and currently only supports Alibaba Cloud.
# It is suitable for situations where the modeling frequency is relatively small.
wefe.job.backend=LOCAL

# Working mode of modeling tasks
# Use integer type definition: Cluster mode=1, stand-alone mode=0
# If work_mode=1 is used, multi-party interaction needs to go through the gateway
# work_mode=0 is only used in stand-alone mode，without gateway interaction, the transmitted data is directly written to mysql，often used with "wefe.job.backend=LOCAL"
wefe.job.work_mode=0

# Computational acceleration scheme
# Contains the following definitions: NONE, GPU
wefe.job.acceleration=NONE

# File upload related functions will uniformly upload files to this directory
wefe.file.upload.dir=/data/wefe_file_upload_dir

# base url of union
wefe.union.base-url=https://wefe.tianmiantech.com/union-service/


# ************************************************
# The configuration for storing data
# ************************************************

# The type of database which data is stored in CLICKHOUSE or LMDB
# LMDB is suitable for the stand-alone mode, and clickhouse is suitable for the cluster mode
db.storage.type=CLICKHOUSE

# If CLICKHOUSE is used, the following configuration is included
# In general, you need to change the url、host、port、username、password , the other use by default
db.storage.clickhouse.driverClassName=ru.yandex.clickhouse.ClickHouseDriver
db.storage.clickhouse.url=jdbc:clickhouse://127.0.0.1:8153
db.storage.clickhouse.host=127.0.0.1
db.storage.clickhouse.tcp.port=9000
db.storage.clickhouse.username=welab
db.storage.clickhouse.password=pwd
db.storage.clickhouse.initialSize=1
db.storage.clickhouse.maxActive=50
db.storage.clickhouse.minIdle=1
db.storage.clickhouse.maxWait=60000
db.storage.clickhouse.testWhileIdle=true
db.storage.clickhouse.validationQuery=SELECT 1
db.storage.clickhouse.timeBetweenEvictionRunsMillis=5000
db.storage.clickhouse.minEvictableIdleTimeMillis=10000
db.storage.clickhouse.removeAbandoned=true
db.storage.clickhouse.removeAbandonedTimeout=300
db.storage.clickhouse.logAbandoned=true
# The batch size of written to CLICKHOUSE in bulk，Units: M(support for sub-counts)
db.storage.clickhouse.optimal.insert.byte.size=1

# If LMDB is used, the following configuration is included
lmdb.database.name=lmdbtest
lmdb.max.size=256
lmdb.database.count=10
lmdb.path=/data/lmdb
lmdb.partitions=8
# ************************************************
# The configuration for business database mysql
# mysql is used to save modeling processes, modeling information, member information, and more
# ************************************************
db.mysql.url=jdbc:mysql://127.0.0.1:3306/wefe_board?characterEncoding=UTF-8&useSSL=false&useUnicode=true&serverTimezone=GMT%2B8
db.mysql.host=127.0.0.1
db.mysql.port=3306
db.mysql.database=wefe_board
db.mysql.username=wefe
db.mysql.password=O*****DDx
# ************************************************
# The configuration for flow
# ************************************************

# The root of the flow log, which supports relative paths
flow.log.root.path=./logs

# If you are using the spark backend, the following configuration is required
flow.spark.submit.default.driver.memory=1g
flow.spark.submit.default.driver.maxResultSize=1g
flow.spark.submit.default.num.executors=1
flow.spark.submit.default.executor.memory=1g
flow.spark.submit.default.executor.cores=1
flow.spark.default.num.slices=1


# ************************************************
# If you are using the fc backend, the following configuration is required
# ************************************************

# the type of intermediate data in function calculates，only ots is supported
fc.storage.type=oss

# the region of function calculates
fc.region=cn-shenzhen

# the alias for the function call
fc.qualifier=LATEST

# the service name for the function call
fc.service.name=wefe-fc

# the account ID for the function call
fc.account_id=294***9042

# the access key id for the function call
fc.access_key_id=LTA***ND7

# the access key secret for the function call
fc.access_key_secret=nxL***sfv

# the vpc id for the function call
fc.vpc_id="xxx"

# the v switch ids for the function call
fc.v_switch_ids="xxx"

# the security group id for the function call
fc.security_group_id="xxx"

# fc account type: api or admin
fc.account_type=admin

# the end point for the function call
fc.end_point=https://145*******.cn-shenzhen.fc.aliyuncs.com

# instance name of ots
fc.ots.instance_name=fc-***

# the end point of the ots internal and external network
fc.ots.internal_end_point=https://fc-***.cn-shenzhen.ots.aliyuncs.com
fc.ots.end_point=https://fc-***.cn-shenzhen.ots.aliyuncs.com

# Used to send intermediate data generated during calculations at oss
fc.cloud_store.temp_auth_internal_end_point=https://*********.aliyuncs.com
fc.cloud_store.temp_auth_end_point=https://*********.aliyuncs.com
fc.cloud_store.temp_auth_role_arn=acs:ram::145*******:role/wefe-fc-ossread
fc.cloud_store.temp_auth_role_session_name=tianmian
fc.cloud_store.temp_auth_duration_seconds=3600


# ************************************************
# oss configuration for fc
# ************************************************
fc.oss.bucket_name=****-*c
fc.oss.endpoint=http://*****.aliyuncs.com
fc.oss.internal_endpoint=http://*********.aliyuncs.com

